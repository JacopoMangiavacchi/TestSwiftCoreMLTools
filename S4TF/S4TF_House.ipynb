{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TO4FT9bUohHx"
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RgQazsBcohH5",
    "outputId": "c5f63b76-3009-4725-ef9d-caccf24671c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 14 101 14\r\n",
      "405 13 405 1 101 13 101 1\r\n",
      "5265 405 1313 101\r\n"
     ]
    }
   ],
   "source": [
    "let trainCSV = try String(contentsOfFile:\"../data/train.csv\", encoding: String.Encoding.utf8)\n",
    "let testCSV = try String(contentsOfFile:\"../data/test.csv\", encoding: String.Encoding.utf8)\n",
    "\n",
    "let trainRecords: [[Float]] = trainCSV.split(separator: \"\\n\").map{ String($0).split(separator: \",\").compactMap{ Float(String($0)) } }\n",
    "let testRecords: [[Float]] = testCSV.split(separator: \"\\n\").map{ String($0).split(separator: \",\").compactMap{ Float(String($0)) } }\n",
    "\n",
    "let numTrainRecords = trainRecords.count\n",
    "let numTrainColumns = trainRecords[0].count\n",
    "let numTestRecords = testRecords.count\n",
    "let numTestColumns = testRecords[0].count\n",
    "\n",
    "print(numTrainRecords, numTrainColumns, numTestRecords, numTestColumns)\n",
    "\n",
    "let xTrain = trainRecords.map{ Array($0[0..<numTrainColumns-1]) }\n",
    "let yTrain = trainRecords.map{ [$0[numTrainColumns-1]] }\n",
    "let xTest = testRecords.map{ Array($0[0..<numTestColumns-1]) }\n",
    "let yTest = testRecords.map{ [$0[numTestColumns-1]] }\n",
    "\n",
    "print(xTrain.count, xTrain[0].count, yTrain.count, yTrain[0].count,\n",
    "      xTest.count, xTest[0].count, yTest.count, yTest[0].count)\n",
    "\n",
    "let xAllTrain = Array(xTrain.joined())\n",
    "let yAllTrain = Array(yTrain.joined())\n",
    "let xAllTest = Array(xTest.joined())\n",
    "let yAllTest = Array(yTest.joined())\n",
    "\n",
    "print(xAllTrain.count, yAllTrain.count, xAllTest.count, yAllTest.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qlhl7tOaohH_",
    "outputId": "1eef7f0c-fa9d-4f83-a1a0-8ea555fbe3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405, 13] [405] [101, 13] [101]\r\n"
     ]
    }
   ],
   "source": [
    "let XTrain = Tensor<Float>(xAllTrain).reshaped(to: TensorShape([numTrainRecords, numTrainColumns-1]))\n",
    "let YTrain = Tensor<Float>(yAllTrain)\n",
    "let XTest = Tensor<Float>(xAllTest).reshaped(to: TensorShape([numTestRecords, numTestColumns-1]))\n",
    "let YTest = Tensor<Float>(yAllTest)\n",
    "\n",
    "print(XTrain.shape, YTrain.shape, XTest.shape, YTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDJZCCgqohIC"
   },
   "outputs": [],
   "source": [
    "struct RegressionModel: Layer {\n",
    "    var layer1 = Dense<Float>(inputSize: 13, outputSize: 64, activation: relu)\n",
    "    var layer2 = Dense<Float>(inputSize: 64, outputSize: 32, activation: relu)\n",
    "    var layer3 = Dense<Float>(inputSize: 32, outputSize: 1)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: layer1, layer2, layer3)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = RegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK0Vj7bSohIF"
   },
   "outputs": [],
   "source": [
    "let optimizer = RMSProp(for: model, learningRate: 0.001)\n",
    "Context.local.learningPhase = .training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gY8C7yHJohIH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 604.4277\n",
      "Loss: 593.51636\n",
      "Loss: 585.7966\n",
      "Loss: 579.3233\n",
      "Loss: 573.486\n",
      "Loss: 568.0008\n",
      "Loss: 562.7851\n",
      "Loss: 557.70764\n",
      "Loss: 552.6743\n",
      "Loss: 547.7055\n",
      "Loss: 542.7961\n",
      "Loss: 537.951\n",
      "Loss: 533.11725\n",
      "Loss: 528.3087\n",
      "Loss: 523.5155\n",
      "Loss: 518.7375\n",
      "Loss: 513.91437\n",
      "Loss: 509.06757\n",
      "Loss: 504.22372\n",
      "Loss: 499.40027\n",
      "Loss: 494.59094\n",
      "Loss: 489.77972\n",
      "Loss: 484.9583\n",
      "Loss: 480.1252\n",
      "Loss: 475.28183\n",
      "Loss: 470.42206\n",
      "Loss: 465.5454\n",
      "Loss: 460.6417\n",
      "Loss: 455.70224\n",
      "Loss: 450.72345\n",
      "Loss: 445.71255\n",
      "Loss: 440.6655\n",
      "Loss: 435.57404\n",
      "Loss: 430.4449\n",
      "Loss: 425.2821\n",
      "Loss: 420.08575\n",
      "Loss: 414.85724\n",
      "Loss: 409.60434\n",
      "Loss: 404.329\n",
      "Loss: 399.03064\n",
      "Loss: 393.7015\n",
      "Loss: 388.34515\n",
      "Loss: 382.96805\n",
      "Loss: 377.5761\n",
      "Loss: 372.17487\n",
      "Loss: 366.76825\n",
      "Loss: 361.36542\n",
      "Loss: 355.9687\n",
      "Loss: 350.5769\n",
      "Loss: 345.19376\n",
      "Loss: 339.82382\n",
      "Loss: 334.46783\n",
      "Loss: 329.12973\n",
      "Loss: 323.81317\n",
      "Loss: 318.5189\n",
      "Loss: 313.2489\n",
      "Loss: 308.00827\n",
      "Loss: 302.80176\n",
      "Loss: 297.63004\n",
      "Loss: 292.49615\n",
      "Loss: 287.40277\n",
      "Loss: 282.3514\n",
      "Loss: 277.35004\n",
      "Loss: 272.40283\n",
      "Loss: 267.51093\n",
      "Loss: 262.6767\n",
      "Loss: 257.90323\n",
      "Loss: 253.19264\n",
      "Loss: 248.54639\n",
      "Loss: 243.96837\n",
      "Loss: 239.46252\n",
      "Loss: 235.03098\n",
      "Loss: 230.67511\n",
      "Loss: 226.39668\n",
      "Loss: 222.19708\n",
      "Loss: 218.07808\n",
      "Loss: 214.0402\n",
      "Loss: 210.08481\n",
      "Loss: 206.21169\n",
      "Loss: 202.42105\n",
      "Loss: 198.71484\n",
      "Loss: 195.09401\n",
      "Loss: 191.55922\n",
      "Loss: 188.11014\n",
      "Loss: 184.74695\n",
      "Loss: 181.47006\n",
      "Loss: 178.28012\n",
      "Loss: 175.17851\n",
      "Loss: 172.16551\n",
      "Loss: 169.23987\n",
      "Loss: 166.40085\n",
      "Loss: 163.64839\n",
      "Loss: 160.98105\n",
      "Loss: 158.399\n",
      "Loss: 155.90135\n",
      "Loss: 153.48518\n",
      "Loss: 151.14738\n",
      "Loss: 148.88905\n",
      "Loss: 146.70764\n",
      "Loss: 144.60042\n",
      "Loss: 142.5647\n",
      "Loss: 140.59953\n",
      "Loss: 138.70341\n",
      "Loss: 136.8734\n",
      "Loss: 135.10568\n",
      "Loss: 133.39807\n",
      "Loss: 131.74614\n",
      "Loss: 130.14903\n",
      "Loss: 128.60362\n",
      "Loss: 127.10802\n",
      "Loss: 125.65932\n",
      "Loss: 124.25314\n",
      "Loss: 122.88772\n",
      "Loss: 121.56379\n",
      "Loss: 120.279594\n",
      "Loss: 119.03301\n",
      "Loss: 117.82255\n",
      "Loss: 116.64593\n",
      "Loss: 115.502174\n",
      "Loss: 114.39049\n",
      "Loss: 113.30821\n",
      "Loss: 112.25444\n",
      "Loss: 111.22861\n",
      "Loss: 110.22778\n",
      "Loss: 109.24983\n",
      "Loss: 108.281105\n",
      "Loss: 107.32849\n",
      "Loss: 106.40061\n",
      "Loss: 105.49973\n",
      "Loss: 104.62693\n",
      "Loss: 103.78039\n",
      "Loss: 102.95812\n",
      "Loss: 102.160545\n",
      "Loss: 101.38781\n",
      "Loss: 100.63832\n",
      "Loss: 99.91319\n",
      "Loss: 99.21229\n",
      "Loss: 98.5345\n",
      "Loss: 97.87994\n",
      "Loss: 97.24813\n",
      "Loss: 96.63953\n",
      "Loss: 96.05311\n",
      "Loss: 95.487015\n",
      "Loss: 94.943794\n",
      "Loss: 94.421425\n",
      "Loss: 93.91857\n",
      "Loss: 93.43395\n",
      "Loss: 92.97012\n",
      "Loss: 92.52703\n",
      "Loss: 92.10404\n",
      "Loss: 91.700554\n",
      "Loss: 91.31614\n",
      "Loss: 90.949745\n",
      "Loss: 90.59974\n",
      "Loss: 90.26652\n",
      "Loss: 89.94833\n",
      "Loss: 89.644104\n",
      "Loss: 89.35235\n",
      "Loss: 89.073906\n",
      "Loss: 88.8071\n",
      "Loss: 88.54993\n",
      "Loss: 88.30275\n",
      "Loss: 88.066536\n",
      "Loss: 87.83908\n",
      "Loss: 87.6213\n",
      "Loss: 87.41169\n",
      "Loss: 87.20901\n",
      "Loss: 87.01407\n",
      "Loss: 86.826\n",
      "Loss: 86.64422\n",
      "Loss: 86.46889\n",
      "Loss: 86.29908\n",
      "Loss: 86.134544\n",
      "Loss: 85.97466\n",
      "Loss: 85.81978\n",
      "Loss: 85.669785\n",
      "Loss: 85.52439\n",
      "Loss: 85.38381\n",
      "Loss: 85.24764\n",
      "Loss: 85.115685\n",
      "Loss: 84.9872\n",
      "Loss: 84.86262\n",
      "Loss: 84.74182\n",
      "Loss: 84.62436\n",
      "Loss: 84.51035\n",
      "Loss: 84.39998\n",
      "Loss: 84.29289\n",
      "Loss: 84.18803\n",
      "Loss: 84.08623\n",
      "Loss: 83.987564\n",
      "Loss: 83.89295\n",
      "Loss: 83.802155\n",
      "Loss: 83.71455\n",
      "Loss: 83.629944\n",
      "Loss: 83.54912\n",
      "Loss: 83.4738\n",
      "Loss: 83.41056\n",
      "Loss: 83.37025\n",
      "Loss: 83.33262\n",
      "Loss: 83.267525\n",
      "Loss: 83.180565\n",
      "Loss: 83.104065\n",
      "Loss: 83.03546\n",
      "Loss: 82.97455\n",
      "Loss: 82.91738\n",
      "Loss: 82.86284\n",
      "Loss: 82.81014\n",
      "Loss: 82.75949\n",
      "Loss: 82.711395\n",
      "Loss: 82.66611\n",
      "Loss: 82.624374\n",
      "Loss: 82.58747\n",
      "Loss: 82.55305\n",
      "Loss: 82.519516\n",
      "Loss: 82.478935\n",
      "Loss: 82.43525\n",
      "Loss: 82.38751\n",
      "Loss: 82.34305\n",
      "Loss: 82.2999\n",
      "Loss: 82.26074\n",
      "Loss: 82.22224\n",
      "Loss: 82.18706\n",
      "Loss: 82.15331\n",
      "Loss: 82.12229\n",
      "Loss: 82.09293\n",
      "Loss: 82.06647\n",
      "Loss: 82.03992\n",
      "Loss: 82.01476\n",
      "Loss: 81.98643\n",
      "Loss: 81.95826\n",
      "Loss: 81.92706\n",
      "Loss: 81.89743\n",
      "Loss: 81.86695\n",
      "Loss: 81.83927\n",
      "Loss: 81.811966\n",
      "Loss: 81.787384\n",
      "Loss: 81.76295\n",
      "Loss: 81.74095\n",
      "Loss: 81.7191\n",
      "Loss: 81.69926\n",
      "Loss: 81.67825\n",
      "Loss: 81.65921\n",
      "Loss: 81.637436\n",
      "Loss: 81.61671\n",
      "Loss: 81.594154\n",
      "Loss: 81.57425\n",
      "Loss: 81.55314\n",
      "Loss: 81.53412\n",
      "Loss: 81.51317\n",
      "Loss: 81.492805\n",
      "Loss: 81.47078\n",
      "Loss: 81.45071\n",
      "Loss: 81.43026\n",
      "Loss: 81.41327\n",
      "Loss: 81.39891\n",
      "Loss: 81.39118\n",
      "Loss: 81.38666\n",
      "Loss: 81.380165\n",
      "Loss: 81.35779\n",
      "Loss: 81.33084\n",
      "Loss: 81.30228\n",
      "Loss: 81.27993\n",
      "Loss: 81.26033\n",
      "Loss: 81.24452\n",
      "Loss: 81.232544\n",
      "Loss: 81.226654\n",
      "Loss: 81.22869\n",
      "Loss: 81.22933\n",
      "Loss: 81.21535\n",
      "Loss: 81.18644\n",
      "Loss: 81.16128\n",
      "Loss: 81.14018\n",
      "Loss: 81.1257\n",
      "Loss: 81.11736\n",
      "Loss: 81.121254\n",
      "Loss: 81.13694\n",
      "Loss: 81.14934\n",
      "Loss: 81.12531\n",
      "Loss: 81.09181\n",
      "Loss: 81.05857\n",
      "Loss: 81.03658\n",
      "Loss: 81.01943\n",
      "Loss: 81.00651\n",
      "Loss: 80.99583\n",
      "Loss: 80.98794\n",
      "Loss: 80.982864\n",
      "Loss: 80.98122\n",
      "Loss: 80.97962\n",
      "Loss: 80.975586\n",
      "Loss: 80.96359\n",
      "Loss: 80.95055\n",
      "Loss: 80.9375\n",
      "Loss: 80.931725\n",
      "Loss: 80.92846\n",
      "Loss: 80.92614\n",
      "Loss: 80.911316\n",
      "Loss: 80.893364\n",
      "Loss: 80.87253\n",
      "Loss: 80.857086\n",
      "Loss: 80.84347\n",
      "Loss: 80.83418\n",
      "Loss: 80.82763\n",
      "Loss: 80.82625\n",
      "Loss: 80.8285\n",
      "Loss: 80.8291\n",
      "Loss: 80.82141\n",
      "Loss: 80.804184\n",
      "Loss: 80.78744\n",
      "Loss: 80.7727\n",
      "Loss: 80.76383\n",
      "Loss: 80.76106\n",
      "Loss: 80.770584\n",
      "Loss: 80.79034\n",
      "Loss: 80.805115\n",
      "Loss: 80.78326\n",
      "Loss: 80.75318\n",
      "Loss: 80.7235\n",
      "Loss: 80.70539\n",
      "Loss: 80.69192\n",
      "Loss: 80.682625\n",
      "Loss: 80.67502\n",
      "Loss: 80.67015\n",
      "Loss: 80.668045\n",
      "Loss: 80.6712\n",
      "Loss: 80.67824\n",
      "Loss: 80.68605\n",
      "Loss: 80.68034\n",
      "Loss: 80.66792\n",
      "Loss: 80.65\n",
      "Loss: 80.63961\n",
      "Loss: 80.633705\n",
      "Loss: 80.63616\n",
      "Loss: 80.635735\n",
      "Loss: 80.631004\n",
      "Loss: 80.61504\n",
      "Loss: 80.60105\n",
      "Loss: 80.58748\n",
      "Loss: 80.57891\n",
      "Loss: 80.57295\n",
      "Loss: 80.57087\n",
      "Loss: 80.57108\n",
      "Loss: 80.57099\n",
      "Loss: 80.56774\n",
      "Loss: 80.558945\n",
      "Loss: 80.549164\n",
      "Loss: 80.53896\n",
      "Loss: 80.53407\n",
      "Loss: 80.53521\n",
      "Loss: 80.54839\n",
      "Loss: 80.56761\n",
      "Loss: 80.576996\n",
      "Loss: 80.55308\n",
      "Loss: 80.526215\n",
      "Loss: 80.50186\n",
      "Loss: 80.48715\n",
      "Loss: 80.476875\n",
      "Loss: 80.469955\n",
      "Loss: 80.46486\n",
      "Loss: 80.46201\n",
      "Loss: 80.461975\n",
      "Loss: 80.46668\n",
      "Loss: 80.47772\n",
      "Loss: 80.49412\n",
      "Loss: 80.497696\n",
      "Loss: 80.48579\n",
      "Loss: 80.46207\n",
      "Loss: 80.44542\n",
      "Loss: 80.434\n",
      "Loss: 80.430374\n",
      "Loss: 80.43294\n",
      "Loss: 80.44218\n",
      "Loss: 80.44697\n",
      "Loss: 80.443405\n",
      "Loss: 80.42809\n",
      "Loss: 80.4144\n",
      "Loss: 80.40338\n",
      "Loss: 80.39676\n",
      "Loss: 80.3936\n",
      "Loss: 80.392845\n",
      "Loss: 80.394035\n",
      "Loss: 80.39257\n",
      "Loss: 80.38999\n",
      "Loss: 80.38361\n",
      "Loss: 80.37972\n",
      "Loss: 80.37825\n",
      "Loss: 80.38565\n",
      "Loss: 80.39882\n",
      "Loss: 80.412636\n",
      "Loss: 80.40325\n",
      "Loss: 80.383675\n",
      "Loss: 80.35893\n",
      "Loss: 80.34362\n",
      "Loss: 80.33222\n",
      "Loss: 80.325455\n",
      "Loss: 80.32043\n",
      "Loss: 80.31762\n",
      "Loss: 80.31655\n",
      "Loss: 80.31866\n",
      "Loss: 80.32472\n",
      "Loss: 80.338875\n",
      "Loss: 80.357254\n",
      "Loss: 80.369934\n",
      "Loss: 80.353386\n",
      "Loss: 80.3303\n",
      "Loss: 80.307236\n",
      "Loss: 80.293976\n",
      "Loss: 80.284874\n",
      "Loss: 80.28056\n",
      "Loss: 80.28046\n",
      "Loss: 80.28905\n",
      "Loss: 80.31013\n",
      "Loss: 80.33492\n",
      "Loss: 80.32799\n",
      "Loss: 80.30767\n",
      "Loss: 80.283325\n",
      "Loss: 80.27064\n",
      "Loss: 80.26403\n",
      "Loss: 80.26342\n",
      "Loss: 80.26761\n",
      "Loss: 80.272705\n",
      "Loss: 80.27571\n",
      "Loss: 80.27094\n",
      "Loss: 80.26539\n",
      "Loss: 80.25953\n",
      "Loss: 80.26074\n",
      "Loss: 80.2668\n",
      "Loss: 80.27937\n",
      "Loss: 80.283844\n",
      "Loss: 80.2785\n",
      "Loss: 80.25896\n",
      "Loss: 80.24364\n",
      "Loss: 80.230095\n",
      "Loss: 80.222374\n",
      "Loss: 80.21656\n",
      "Loss: 80.21365\n",
      "Loss: 80.21212\n",
      "Loss: 80.21361\n",
      "Loss: 80.217514\n",
      "Loss: 80.22779\n",
      "Loss: 80.244545\n",
      "Loss: 80.26457\n",
      "Loss: 80.26117\n",
      "Loss: 80.240746\n",
      "Loss: 80.214035\n",
      "Loss: 80.19801\n",
      "Loss: 80.18708\n",
      "Loss: 80.18102\n",
      "Loss: 80.17728\n",
      "Loss: 80.176765\n",
      "Loss: 80.18178\n",
      "Loss: 80.20165\n",
      "Loss: 80.24148\n",
      "Loss: 80.26593\n",
      "Loss: 80.23166\n",
      "Loss: 80.199455\n",
      "Loss: 80.17575\n",
      "Loss: 80.16573\n",
      "Loss: 80.162544\n",
      "Loss: 80.166405\n",
      "Loss: 80.17781\n",
      "Loss: 80.19113\n",
      "Loss: 80.19566\n",
      "Loss: 80.18384\n",
      "Loss: 80.17178\n",
      "Loss: 80.16195\n",
      "Loss: 80.160065\n",
      "Loss: 80.16477\n",
      "Loss: 80.17913\n",
      "Loss: 80.19395\n",
      "Loss: 80.19994\n",
      "Loss: 80.18349\n",
      "Loss: 80.16607\n",
      "Loss: 80.1488\n",
      "Loss: 80.13888\n",
      "Loss: 80.13199\n",
      "Loss: 80.128716\n",
      "Loss: 80.12757\n",
      "Loss: 80.129745\n",
      "Loss: 80.13594\n",
      "Loss: 80.15035\n",
      "Loss: 80.16929\n",
      "Loss: 80.180466\n",
      "Loss: 80.16516\n",
      "Loss: 80.14554\n",
      "Loss: 80.12664\n",
      "Loss: 80.11632\n",
      "Loss: 80.11032\n",
      "Loss: 80.110115\n",
      "Loss: 80.11797\n",
      "Loss: 80.14279\n",
      "Loss: 80.17215\n",
      "Loss: 80.175964\n",
      "Loss: 80.14412\n",
      "Loss: 80.12061\n",
      "Loss: 80.10428\n",
      "Loss: 80.097466\n",
      "Loss: 80.09623\n",
      "Loss: 80.10135\n",
      "Loss: 80.1124\n",
      "Loss: 80.12339\n",
      "Loss: 80.12675\n",
      "Loss: 80.11751\n",
      "Loss: 80.108665\n",
      "Loss: 80.102135\n",
      "Loss: 80.10447\n",
      "Loss: 80.11345\n",
      "Loss: 80.12885\n",
      "Loss: 80.13375\n",
      "Loss: 80.12732\n",
      "Loss: 80.1066\n",
      "Loss: 80.0919\n",
      "Loss: 80.07904\n",
      "Loss: 80.072464\n",
      "Loss: 80.06804\n",
      "Loss: 80.06671\n",
      "Loss: 80.0673\n",
      "Loss: 80.07213\n",
      "Loss: 80.08193\n",
      "Loss: 80.10177\n",
      "Loss: 80.12197\n",
      "Loss: 80.126274\n",
      "Loss: 80.10346\n",
      "Loss: 80.081665\n",
      "Loss: 80.06428\n",
      "Loss: 80.05533\n",
      "Loss: 80.04991\n",
      "Loss: 80.04874\n",
      "Loss: 80.05267\n",
      "Loss: 80.07031\n",
      "Loss: 80.10753\n",
      "Loss: 80.13736\n",
      "Loss: 80.11063\n",
      "Loss: 80.079865\n",
      "Loss: 80.05515\n",
      "Loss: 80.044846\n",
      "Loss: 80.040924\n",
      "Loss: 80.04378\n",
      "Loss: 80.05379\n",
      "Loss: 80.06875\n",
      "Loss: 80.08013\n",
      "Loss: 80.075195\n",
      "Loss: 80.065\n",
      "Loss: 80.054276\n",
      "Loss: 80.05167\n",
      "Loss: 80.05558\n",
      "Loss: 80.06827\n",
      "Loss: 80.080124\n",
      "Loss: 80.08494\n",
      "Loss: 80.07054\n",
      "Loss: 80.05573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 80.04007\n",
      "Loss: 80.03131\n",
      "Loss: 80.02496\n",
      "Loss: 80.02232\n",
      "Loss: 80.02132\n",
      "Loss: 80.02367\n",
      "Loss: 80.02939\n",
      "Loss: 80.04262\n",
      "Loss: 80.06355\n",
      "Loss: 80.08544\n",
      "Loss: 80.07938\n",
      "Loss: 80.05827\n",
      "Loss: 80.03358\n",
      "Loss: 80.019516\n",
      "Loss: 80.01031\n",
      "Loss: 80.005905\n",
      "Loss: 80.00349\n",
      "Loss: 80.003815\n",
      "Loss: 80.00807\n",
      "Loss: 80.02449\n",
      "Loss: 80.06844\n",
      "Loss: 80.11735\n",
      "Loss: 80.087654\n",
      "Loss: 80.04597\n",
      "Loss: 80.014305\n",
      "Loss: 80.0019\n",
      "Loss: 79.9969\n",
      "Loss: 79.99905\n",
      "Loss: 80.00919\n",
      "Loss: 80.02795\n",
      "Loss: 80.045456\n",
      "Loss: 80.04115\n",
      "Loss: 80.02795\n",
      "Loss: 80.012184\n",
      "Loss: 80.00524\n",
      "Loss: 80.004234\n",
      "Loss: 80.01255\n",
      "Loss: 80.02796\n",
      "Loss: 80.04776\n",
      "Loss: 80.04981\n",
      "Loss: 80.03853\n",
      "Loss: 80.016235\n",
      "Loss: 80.00212\n",
      "Loss: 79.99127\n",
      "Loss: 79.98614\n",
      "Loss: 79.98311\n",
      "Loss: 79.98343\n",
      "Loss: 79.98621\n",
      "Loss: 79.99499\n",
      "Loss: 80.011086\n",
      "Loss: 80.03596\n",
      "Loss: 80.04603\n",
      "Loss: 80.03463\n",
      "Loss: 80.00827\n",
      "Loss: 79.99085\n",
      "Loss: 79.978806\n",
      "Loss: 79.97273\n",
      "Loss: 79.96914\n",
      "Loss: 79.96811\n",
      "Loss: 79.96892\n",
      "Loss: 79.97394\n",
      "Loss: 79.98945\n",
      "Loss: 80.03732\n",
      "Loss: 80.095184\n",
      "Loss: 80.0756\n",
      "Loss: 80.010216\n",
      "Loss: 79.98024\n",
      "Loss: 79.965004\n",
      "Loss: 79.960304\n",
      "Loss: 79.96064\n",
      "Loss: 79.968155\n",
      "Loss: 79.98543\n",
      "Loss: 80.00749\n",
      "Loss: 80.01684\n",
      "Loss: 80.00184\n",
      "Loss: 79.98552\n",
      "Loss: 79.97217\n",
      "Loss: 79.967606\n",
      "Loss: 79.9694\n",
      "Loss: 79.98155\n",
      "Loss: 80.00313\n",
      "Loss: 80.02746\n",
      "Loss: 80.0242\n",
      "Loss: 80.006645\n",
      "Loss: 79.980736\n",
      "Loss: 79.96643\n",
      "Loss: 79.95656\n",
      "Loss: 79.95222\n",
      "Loss: 79.95008\n",
      "Loss: 79.951126\n",
      "Loss: 79.95526\n",
      "Loss: 79.96627\n",
      "Loss: 79.98565\n",
      "Loss: 80.0111\n",
      "Loss: 80.015045\n",
      "Loss: 79.99914\n",
      "Loss: 79.97328\n",
      "Loss: 79.95762\n",
      "Loss: 79.94718\n",
      "Loss: 79.94207\n",
      "Loss: 79.93917\n",
      "Loss: 79.93869\n",
      "Loss: 79.94005\n",
      "Loss: 79.94577\n",
      "Loss: 79.960106\n",
      "Loss: 79.99394\n",
      "Loss: 80.03642\n",
      "Loss: 80.043625\n",
      "Loss: 80.01541\n",
      "Loss: 79.97744\n",
      "Loss: 79.961525\n",
      "Loss: 79.95315\n",
      "Loss: 79.95323\n",
      "Loss: 79.956116\n",
      "Loss: 79.96141\n",
      "Loss: 79.96419\n",
      "Loss: 79.96477\n",
      "Loss: 79.96039\n",
      "Loss: 79.95598\n",
      "Loss: 79.95006\n",
      "Loss: 79.94694\n",
      "Loss: 79.9447\n",
      "Loss: 79.946266\n",
      "Loss: 79.949326\n",
      "Loss: 79.95705\n",
      "Loss: 79.963295\n",
      "Loss: 79.969894\n",
      "Loss: 79.965485\n",
      "Loss: 79.960266\n",
      "Loss: 79.94876\n",
      "Loss: 79.942764\n",
      "Loss: 79.937256\n",
      "Loss: 79.93871\n",
      "Loss: 79.945335\n",
      "Loss: 79.960945\n",
      "Loss: 79.975395\n",
      "Loss: 79.972855\n",
      "Loss: 79.959206\n",
      "Loss: 79.94241\n",
      "Loss: 79.93428\n",
      "Loss: 79.931656\n",
      "Loss: 79.93711\n",
      "Loss: 79.94909\n",
      "Loss: 79.96734\n",
      "Loss: 79.97735\n",
      "Loss: 79.9757\n",
      "Loss: 79.95671\n",
      "Loss: 79.94199\n",
      "Loss: 79.92805\n",
      "Loss: 79.92114\n",
      "Loss: 79.91637\n",
      "Loss: 79.91508\n",
      "Loss: 79.91549\n",
      "Loss: 79.91942\n",
      "Loss: 79.926575\n",
      "Loss: 79.94101\n",
      "Loss: 79.96005\n",
      "Loss: 79.97772\n",
      "Loss: 79.970894\n",
      "Loss: 79.95265\n",
      "Loss: 79.93039\n",
      "Loss: 79.917915\n",
      "Loss: 79.90986\n",
      "Loss: 79.908035\n",
      "Loss: 79.91117\n",
      "Loss: 79.9254\n",
      "Loss: 79.95249\n",
      "Loss: 79.97766\n",
      "Loss: 79.97915\n",
      "Loss: 79.952705\n",
      "Loss: 79.93328\n",
      "Loss: 79.91835\n",
      "Loss: 79.914\n",
      "Loss: 79.91412\n",
      "Loss: 79.9215\n",
      "Loss: 79.93289\n",
      "Loss: 79.94561\n",
      "Loss: 79.9483\n",
      "Loss: 79.94241\n",
      "Loss: 79.92851\n",
      "Loss: 79.917915\n",
      "Loss: 79.90927\n",
      "Loss: 79.90553\n",
      "Loss: 79.90422\n",
      "Loss: 79.90766\n",
      "Loss: 79.914955\n",
      "Loss: 79.92925\n",
      "Loss: 79.941864\n",
      "Loss: 79.94938\n",
      "Loss: 79.937614\n",
      "Loss: 79.92628\n",
      "Loss: 79.912285\n",
      "Loss: 79.90703\n",
      "Loss: 79.90632\n",
      "Loss: 79.91505\n",
      "Loss: 79.92992\n",
      "Loss: 79.940475\n",
      "Loss: 79.93812\n",
      "Loss: 79.92306\n",
      "Loss: 79.91225\n",
      "Loss: 79.905304\n",
      "Loss: 79.90634\n",
      "Loss: 79.913315\n",
      "Loss: 79.92779\n",
      "Loss: 79.94076\n",
      "Loss: 79.946724\n",
      "Loss: 79.93403\n",
      "Loss: 79.9205\n",
      "Loss: 79.90482\n",
      "Loss: 79.896324\n",
      "Loss: 79.889946\n",
      "Loss: 79.88777\n",
      "Loss: 79.88703\n",
      "Loss: 79.88925\n",
      "Loss: 79.893875\n",
      "Loss: 79.90404\n",
      "Loss: 79.91996\n",
      "Loss: 79.94378\n",
      "Loss: 79.955215\n",
      "Loss: 79.94575\n",
      "Loss: 79.91841\n",
      "Loss: 79.89982\n",
      "Loss: 79.88732\n",
      "Loss: 79.883064\n",
      "Loss: 79.88385\n",
      "Loss: 79.893616\n",
      "Loss: 79.913765\n",
      "Loss: 79.93757\n",
      "Loss: 79.94758\n",
      "Loss: 79.930534\n",
      "Loss: 79.91324\n",
      "Loss: 79.89656\n",
      "Loss: 79.89025\n",
      "Loss: 79.888214\n",
      "Loss: 79.893456\n",
      "Loss: 79.90369\n",
      "Loss: 79.918686\n",
      "Loss: 79.926865\n",
      "Loss: 79.924706\n",
      "Loss: 79.91013\n",
      "Loss: 79.89751\n",
      "Loss: 79.88648\n",
      "Loss: 79.880905\n",
      "Loss: 79.87787\n",
      "Loss: 79.87898\n",
      "Loss: 79.88345\n",
      "Loss: 79.894905\n",
      "Loss: 79.91139\n",
      "Loss: 79.9297\n",
      "Loss: 79.92778\n",
      "Loss: 79.91714\n",
      "Loss: 79.89721\n",
      "Loss: 79.887054\n",
      "Loss: 79.88109\n",
      "Loss: 79.884346\n",
      "Loss: 79.89511\n",
      "Loss: 79.91022\n",
      "Loss: 79.91822\n",
      "Loss: 79.90896\n",
      "Loss: 79.89703\n",
      "Loss: 79.885345\n",
      "Loss: 79.8818\n",
      "Loss: 79.883514\n",
      "Loss: 79.8933\n",
      "Loss: 79.90758\n",
      "Loss: 79.922714\n",
      "Loss: 79.92169\n",
      "Loss: 79.91202\n",
      "Loss: 79.89341\n",
      "Loss: 79.88161\n",
      "Loss: 79.87185\n",
      "Loss: 79.8674\n",
      "Loss: 79.8647\n",
      "Loss: 79.86512\n",
      "Loss: 79.86706\n",
      "Loss: 79.87277\n",
      "Loss: 79.88209\n",
      "Loss: 79.899475\n",
      "Loss: 79.92148\n",
      "Loss: 79.939384\n",
      "Loss: 79.9257\n",
      "Loss: 79.90246\n",
      "Loss: 79.87903\n",
      "Loss: 79.86777\n",
      "Loss: 79.86237\n",
      "Loss: 79.86478\n",
      "Loss: 79.874596\n",
      "Loss: 79.89407\n",
      "Loss: 79.91478\n",
      "Loss: 79.91758\n",
      "Loss: 79.907455\n",
      "Loss: 79.88749\n",
      "Loss: 79.876236\n",
      "Loss: 79.868614\n",
      "Loss: 79.86855\n",
      "Loss: 79.872925\n",
      "Loss: 79.88479\n",
      "Loss: 79.89891\n",
      "Loss: 79.90949\n",
      "Loss: 79.90348\n",
      "Loss: 79.89126\n",
      "Loss: 79.87585\n",
      "Loss: 79.86624\n",
      "Loss: 79.85942\n",
      "Loss: 79.857086\n",
      "Loss: 79.85715\n",
      "Loss: 79.86182\n",
      "Loss: 79.87167\n",
      "Loss: 79.89091\n",
      "Loss: 79.90963\n",
      "Loss: 79.91832\n",
      "Loss: 79.89986\n",
      "Loss: 79.88326\n",
      "Loss: 79.86737\n",
      "Loss: 79.862274\n",
      "Loss: 79.863304\n",
      "Loss: 79.873314\n",
      "Loss: 79.88841\n",
      "Loss: 79.89592\n",
      "Loss: 79.89203\n",
      "Loss: 79.87782\n",
      "Loss: 79.86864\n",
      "Loss: 79.86306\n",
      "Loss: 79.86492\n",
      "Loss: 79.8724\n",
      "Loss: 79.88722\n",
      "Loss: 79.900085\n",
      "Loss: 79.90591\n",
      "Loss: 79.89298\n",
      "Loss: 79.87936\n",
      "Loss: 79.86376\n",
      "Loss: 79.85524\n",
      "Loss: 79.849014\n",
      "Loss: 79.84682\n",
      "Loss: 79.84592\n",
      "Loss: 79.84796\n",
      "Loss: 79.85169\n",
      "Loss: 79.85987\n",
      "Loss: 79.87181\n",
      "Loss: 79.892624\n",
      "Loss: 79.91611\n",
      "Loss: 79.92767\n",
      "Loss: 79.903305\n",
      "Loss: 79.87757\n",
      "Loss: 79.8568\n",
      "Loss: 79.848595\n",
      "Loss: 79.846466\n",
      "Loss: 79.85222\n",
      "Loss: 79.86511\n",
      "Loss: 79.88194\n",
      "Loss: 79.894554\n",
      "Loss: 79.889175\n",
      "Loss: 79.878944\n",
      "Loss: 79.86368\n",
      "Loss: 79.85622\n",
      "Loss: 79.851715\n",
      "Loss: 79.85425\n",
      "Loss: 79.86143\n",
      "Loss: 79.87588\n",
      "Loss: 79.88922\n",
      "Loss: 79.89464\n",
      "Loss: 79.882935\n",
      "Loss: 79.86865\n",
      "Loss: 79.85401\n",
      "Loss: 79.8458\n",
      "Loss: 79.84034\n",
      "Loss: 79.838745\n",
      "Loss: 79.8394\n",
      "Loss: 79.844505\n",
      "Loss: 79.855316\n",
      "Loss: 79.87762\n",
      "Loss: 79.90202\n",
      "Loss: 79.91301\n",
      "Loss: 79.88919\n",
      "Loss: 79.868904\n",
      "Loss: 79.85077\n",
      "Loss: 79.84523\n",
      "Loss: 79.84641\n",
      "Loss: 79.85639\n",
      "Loss: 79.871346\n",
      "Loss: 79.87878\n",
      "Loss: 79.8756\n",
      "Loss: 79.86193\n",
      "Loss: 79.852715\n",
      "Loss: 79.84662\n",
      "Loss: 79.847725\n",
      "Loss: 79.854454\n",
      "Loss: 79.86912\n",
      "Loss: 79.8844\n",
      "Loss: 79.893814\n",
      "Loss: 79.88287\n",
      "Loss: 79.86853\n",
      "Loss: 79.85128\n",
      "Loss: 79.84164\n",
      "Loss: 79.834526\n",
      "Loss: 79.83174\n",
      "Loss: 79.83046\n",
      "Loss: 79.83205\n",
      "Loss: 79.835\n",
      "Loss: 79.84146\n",
      "Loss: 79.84948\n",
      "Loss: 79.862335\n",
      "Loss: 79.87736\n",
      "Loss: 79.901505\n",
      "Loss: 79.91723\n",
      "Loss: 79.90581\n",
      "Loss: 79.86967\n",
      "Loss: 79.847755\n",
      "Loss: 79.83493\n",
      "Loss: 79.83184\n",
      "Loss: 79.83404\n",
      "Loss: 79.84223\n",
      "Loss: 79.85504\n",
      "Loss: 79.86664\n",
      "Loss: 79.8728\n",
      "Loss: 79.865715\n",
      "Loss: 79.85752\n",
      "Loss: 79.84686\n",
      "Loss: 79.84256\n",
      "Loss: 79.84119\n",
      "Loss: 79.846954\n",
      "Loss: 79.858376\n",
      "Loss: 79.87497\n",
      "Loss: 79.88264\n",
      "Loss: 79.877235\n",
      "Loss: 79.85907\n",
      "Loss: 79.84453\n",
      "Loss: 79.833015\n",
      "Loss: 79.82705\n",
      "Loss: 79.82368\n",
      "Loss: 79.82332\n",
      "Loss: 79.825356\n",
      "Loss: 79.83178\n",
      "Loss: 79.84517\n",
      "Loss: 79.87155\n",
      "Loss: 79.90022\n",
      "Loss: 79.90825\n",
      "Loss: 79.877556\n",
      "Loss: 79.853775\n",
      "Loss: 79.83557\n",
      "Loss: 79.830475\n",
      "Loss: 79.8326\n",
      "Loss: 79.84337\n",
      "Loss: 79.85855\n",
      "Loss: 79.86563\n",
      "Loss: 79.861435\n",
      "Loss: 79.84756\n",
      "Loss: 79.83818\n",
      "Loss: 79.8318\n",
      "Loss: 79.83214\n"
     ]
    }
   ],
   "source": [
    "for _ in 0..<1000 {\n",
    "    let 𝛁model = model.gradient { r -> Tensor<Float> in\n",
    "        let ŷ = r(XTrain)\n",
    "        let loss = meanSquaredError(predicted: ŷ, expected: YTrain)\n",
    "        print(\"Loss: \\(loss)\")\n",
    "        return loss\n",
    "    }\n",
    "    optimizer.update(&model, along: 𝛁model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fkf29HLlohIP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF_House.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

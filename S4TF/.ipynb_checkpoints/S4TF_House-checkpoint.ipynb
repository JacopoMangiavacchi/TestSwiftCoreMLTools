{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\", from: \"0.0.3\")\n",
      "\t\tSwiftCoreMLTools\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmppf4x5ck3/swift-install\n",
      "Fetching https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\n",
      "Fetching https://github.com/apple/swift-protobuf.git\n",
      "Cloning https://github.com/apple/swift-protobuf.git\n",
      "Resolving https://github.com/apple/swift-protobuf.git at 1.8.0\n",
      "Cloning https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\n",
      "Resolving https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git at 0.0.3\n",
      "[1/2] Compiling SwiftProtobuf AnyMessageStorage.swift\n",
      "[2/3] Compiling SwiftCoreMLTools Activations.swift\n",
      "[3/4] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[4/4] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-swiftpm-flags -c release\n",
    "%install '.package(url: \"https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\", from: \"0.0.3\")' SwiftCoreMLTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TO4FT9bUohHx"
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "import SwiftCoreMLTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RgQazsBcohH5",
    "outputId": "c5f63b76-3009-4725-ef9d-caccf24671c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 14 101 14\r\n",
      "405 13 405 1 101 13 101 1\r\n",
      "5265 405 1313 101\r\n"
     ]
    }
   ],
   "source": [
    "let trainCSV = try String(contentsOfFile:\"../data/train.csv\", encoding: String.Encoding.utf8)\n",
    "let testCSV = try String(contentsOfFile:\"../data/test.csv\", encoding: String.Encoding.utf8)\n",
    "\n",
    "let trainRecords: [[Float]] = trainCSV.split(separator: \"\\n\").map{ String($0).split(separator: \",\").compactMap{ Float(String($0)) } }\n",
    "let testRecords: [[Float]] = testCSV.split(separator: \"\\n\").map{ String($0).split(separator: \",\").compactMap{ Float(String($0)) } }\n",
    "\n",
    "let numTrainRecords = trainRecords.count\n",
    "let numTrainColumns = trainRecords[0].count\n",
    "let numTestRecords = testRecords.count\n",
    "let numTestColumns = testRecords[0].count\n",
    "\n",
    "print(numTrainRecords, numTrainColumns, numTestRecords, numTestColumns)\n",
    "\n",
    "let xTrain = trainRecords.map{ Array($0[0..<numTrainColumns-1]) }\n",
    "let yTrain = trainRecords.map{ [$0[numTrainColumns-1]] }\n",
    "let xTest = testRecords.map{ Array($0[0..<numTestColumns-1]) }\n",
    "let yTest = testRecords.map{ [$0[numTestColumns-1]] }\n",
    "\n",
    "print(xTrain.count, xTrain[0].count, yTrain.count, yTrain[0].count,\n",
    "      xTest.count, xTest[0].count, yTest.count, yTest[0].count)\n",
    "\n",
    "let xAllTrain = Array(xTrain.joined())\n",
    "let yAllTrain = Array(yTrain.joined())\n",
    "let xAllTest = Array(xTest.joined())\n",
    "let yAllTest = Array(yTest.joined())\n",
    "\n",
    "print(xAllTrain.count, yAllTrain.count, xAllTest.count, yAllTest.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qlhl7tOaohH_",
    "outputId": "1eef7f0c-fa9d-4f83-a1a0-8ea555fbe3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405, 13] [405, 1] [101, 13] [101, 1]\r\n"
     ]
    }
   ],
   "source": [
    "let XTrain = Tensor<Float>(xAllTrain).reshaped(to: TensorShape([numTrainRecords, numTrainColumns-1]))\n",
    "let YTrain = Tensor<Float>(yAllTrain).reshaped(to: TensorShape([numTrainRecords, 1]))\n",
    "let XTest = Tensor<Float>(xAllTest).reshaped(to: TensorShape([numTestRecords, numTestColumns-1]))\n",
    "let YTest = Tensor<Float>(yAllTest).reshaped(to: TensorShape([numTestRecords, 1]))\n",
    "\n",
    "print(XTrain.shape, YTrain.shape, XTest.shape, YTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDJZCCgqohIC"
   },
   "outputs": [],
   "source": [
    "struct RegressionModel: Layer {\n",
    "    var layer1 = Dense<Float>(inputSize: 13, outputSize: 64, activation: relu)\n",
    "    var layer2 = Dense<Float>(inputSize: 64, outputSize: 32, activation: relu)\n",
    "    var layer3 = Dense<Float>(inputSize: 32, outputSize: 1)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: layer1, layer2, layer3)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = RegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK0Vj7bSohIF"
   },
   "outputs": [],
   "source": [
    "let optimizer = RMSProp(for: model, learningRate: 0.001)\n",
    "Context.local.learningPhase = .training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gY8C7yHJohIH"
   },
   "outputs": [],
   "source": [
    "let epochCount = 500\n",
    "let batchSize = 32\n",
    "let numberOfBatch = Int(ceil(Double(xTrain.count) / Double(batchSize)))\n",
    "let shuffle = true\n",
    "\n",
    "func mae(predictions: Tensor<Float>, truths: Tensor<Float>) -> Float {\n",
    "    return abs(Tensor<Float>(predictions - truths)).mean().scalarized()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "L9bU9HsdohIK",
    "outputId": "692b81c5-3286-4e7c-9246-eb56e6a3eaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE: 527.28845, MAE: 21.024227\n",
      "Epoch 2: MSE: 448.95706, MAE: 19.145615\n",
      "Epoch 3: MSE: 371.8916, MAE: 17.078512\n",
      "Epoch 4: MSE: 290.92905, MAE: 14.718288\n",
      "Epoch 5: MSE: 211.92044, MAE: 12.080781\n",
      "Epoch 6: MSE: 142.39896, MAE: 9.468523\n",
      "Epoch 7: MSE: 93.67974, MAE: 7.383197\n",
      "Epoch 8: MSE: 64.12294, MAE: 5.9279895\n",
      "Epoch 9: MSE: 48.277653, MAE: 5.025338\n",
      "Epoch 10: MSE: 39.277237, MAE: 4.484613\n",
      "Epoch 11: MSE: 33.563488, MAE: 4.065484\n",
      "Epoch 12: MSE: 29.436256, MAE: 3.8072298\n",
      "Epoch 13: MSE: 26.583055, MAE: 3.5502284\n",
      "Epoch 14: MSE: 24.471195, MAE: 3.4155972\n",
      "Epoch 15: MSE: 22.703342, MAE: 3.2718396\n",
      "Epoch 16: MSE: 21.292482, MAE: 3.113831\n",
      "Epoch 17: MSE: 20.132822, MAE: 3.0101008\n",
      "Epoch 18: MSE: 19.151756, MAE: 2.9218893\n",
      "Epoch 19: MSE: 18.264875, MAE: 2.8495574\n",
      "Epoch 20: MSE: 17.471004, MAE: 2.7943165\n",
      "Epoch 21: MSE: 16.814466, MAE: 2.7393186\n",
      "Epoch 22: MSE: 16.191317, MAE: 2.6750157\n",
      "Epoch 23: MSE: 15.734031, MAE: 2.6526732\n",
      "Epoch 24: MSE: 15.301475, MAE: 2.5963373\n",
      "Epoch 25: MSE: 14.793852, MAE: 2.5578778\n",
      "Epoch 26: MSE: 14.425038, MAE: 2.5300193\n",
      "Epoch 27: MSE: 14.145645, MAE: 2.4832394\n",
      "Epoch 28: MSE: 13.872914, MAE: 2.4859128\n",
      "Epoch 29: MSE: 13.522307, MAE: 2.4649796\n",
      "Epoch 30: MSE: 13.400177, MAE: 2.446278\n",
      "Epoch 31: MSE: 13.026097, MAE: 2.419708\n",
      "Epoch 32: MSE: 12.898893, MAE: 2.393672\n",
      "Epoch 33: MSE: 12.679321, MAE: 2.376407\n",
      "Epoch 34: MSE: 12.497743, MAE: 2.3556604\n",
      "Epoch 35: MSE: 12.186634, MAE: 2.347042\n",
      "Epoch 36: MSE: 12.20495, MAE: 2.314308\n",
      "Epoch 37: MSE: 11.855031, MAE: 2.2896674\n",
      "Epoch 38: MSE: 11.733583, MAE: 2.288204\n",
      "Epoch 39: MSE: 11.714005, MAE: 2.2687256\n",
      "Epoch 40: MSE: 11.549284, MAE: 2.2480712\n",
      "Epoch 41: MSE: 11.390207, MAE: 2.235869\n",
      "Epoch 42: MSE: 11.313674, MAE: 2.2292628\n",
      "Epoch 43: MSE: 11.1427, MAE: 2.2179205\n",
      "Epoch 44: MSE: 10.937608, MAE: 2.1850445\n",
      "Epoch 45: MSE: 11.005118, MAE: 2.1865137\n",
      "Epoch 46: MSE: 10.826221, MAE: 2.1892903\n",
      "Epoch 47: MSE: 10.69228, MAE: 2.1649466\n",
      "Epoch 48: MSE: 10.607391, MAE: 2.1734009\n",
      "Epoch 49: MSE: 10.491597, MAE: 2.148208\n",
      "Epoch 50: MSE: 10.490117, MAE: 2.135306\n",
      "Epoch 51: MSE: 10.368698, MAE: 2.1341815\n",
      "Epoch 52: MSE: 10.262376, MAE: 2.1112022\n",
      "Epoch 53: MSE: 10.090598, MAE: 2.1093957\n",
      "Epoch 54: MSE: 10.002341, MAE: 2.0885522\n",
      "Epoch 55: MSE: 9.920598, MAE: 2.0699918\n",
      "Epoch 56: MSE: 9.895803, MAE: 2.0709233\n",
      "Epoch 57: MSE: 9.78101, MAE: 2.0665624\n",
      "Epoch 58: MSE: 9.733065, MAE: 2.0725353\n",
      "Epoch 59: MSE: 9.598128, MAE: 2.040635\n",
      "Epoch 60: MSE: 9.612944, MAE: 2.053985\n",
      "Epoch 61: MSE: 9.524715, MAE: 2.0207694\n",
      "Epoch 62: MSE: 9.46766, MAE: 2.0412068\n",
      "Epoch 63: MSE: 9.401227, MAE: 2.0355387\n",
      "Epoch 64: MSE: 9.291768, MAE: 2.015034\n",
      "Epoch 65: MSE: 9.219574, MAE: 2.0238066\n",
      "Epoch 66: MSE: 9.206817, MAE: 2.0013545\n",
      "Epoch 67: MSE: 9.149973, MAE: 2.003963\n",
      "Epoch 68: MSE: 9.014973, MAE: 1.9984899\n",
      "Epoch 69: MSE: 8.985764, MAE: 1.9879476\n",
      "Epoch 70: MSE: 8.93304, MAE: 1.9784373\n",
      "Epoch 71: MSE: 8.822895, MAE: 1.9693574\n",
      "Epoch 72: MSE: 8.777819, MAE: 1.9603841\n",
      "Epoch 73: MSE: 8.692817, MAE: 1.9636506\n",
      "Epoch 74: MSE: 8.654779, MAE: 1.9418855\n",
      "Epoch 75: MSE: 8.712479, MAE: 1.9440713\n",
      "Epoch 76: MSE: 8.600699, MAE: 1.9267478\n",
      "Epoch 77: MSE: 8.521465, MAE: 1.9329867\n",
      "Epoch 78: MSE: 8.408759, MAE: 1.9390473\n",
      "Epoch 79: MSE: 8.380423, MAE: 1.9270589\n",
      "Epoch 80: MSE: 8.330649, MAE: 1.9141841\n",
      "Epoch 81: MSE: 8.292225, MAE: 1.9124097\n",
      "Epoch 82: MSE: 8.199247, MAE: 1.9007494\n",
      "Epoch 83: MSE: 8.146552, MAE: 1.901438\n",
      "Epoch 84: MSE: 8.127984, MAE: 1.8965294\n",
      "Epoch 85: MSE: 8.202227, MAE: 1.8781415\n",
      "Epoch 86: MSE: 8.022216, MAE: 1.8756397\n",
      "Epoch 87: MSE: 7.8088336, MAE: 1.87379\n",
      "Epoch 88: MSE: 7.9248705, MAE: 1.863283\n",
      "Epoch 89: MSE: 7.8691325, MAE: 1.8681821\n",
      "Epoch 90: MSE: 7.7926936, MAE: 1.8543941\n",
      "Epoch 91: MSE: 7.741176, MAE: 1.847528\n",
      "Epoch 92: MSE: 7.6261945, MAE: 1.8392078\n",
      "Epoch 93: MSE: 7.654052, MAE: 1.8395083\n",
      "Epoch 94: MSE: 7.6270423, MAE: 1.8396745\n",
      "Epoch 95: MSE: 7.580319, MAE: 1.8192912\n",
      "Epoch 96: MSE: 7.5253744, MAE: 1.8180112\n",
      "Epoch 97: MSE: 7.47625, MAE: 1.8132066\n",
      "Epoch 98: MSE: 7.463, MAE: 1.8162079\n",
      "Epoch 99: MSE: 7.3510027, MAE: 1.7964058\n",
      "Epoch 100: MSE: 7.1158924, MAE: 1.7815036\n",
      "Epoch 101: MSE: 7.2946057, MAE: 1.7730229\n",
      "Epoch 102: MSE: 7.116199, MAE: 1.7833606\n",
      "Epoch 103: MSE: 7.100779, MAE: 1.7595018\n",
      "Epoch 104: MSE: 7.1364384, MAE: 1.7626649\n",
      "Epoch 105: MSE: 7.16247, MAE: 1.7734349\n",
      "Epoch 106: MSE: 6.963626, MAE: 1.7662976\n",
      "Epoch 107: MSE: 6.9077196, MAE: 1.7556806\n",
      "Epoch 108: MSE: 6.981558, MAE: 1.7480655\n",
      "Epoch 109: MSE: 6.917961, MAE: 1.7532197\n",
      "Epoch 110: MSE: 6.8560004, MAE: 1.7469572\n",
      "Epoch 111: MSE: 6.812009, MAE: 1.7513366\n",
      "Epoch 112: MSE: 6.696357, MAE: 1.7273589\n",
      "Epoch 113: MSE: 6.7660775, MAE: 1.722318\n",
      "Epoch 114: MSE: 6.7579236, MAE: 1.7239503\n",
      "Epoch 115: MSE: 6.628731, MAE: 1.7216276\n",
      "Epoch 116: MSE: 6.5205197, MAE: 1.6949824\n",
      "Epoch 117: MSE: 6.5651317, MAE: 1.689007\n",
      "Epoch 118: MSE: 6.3128033, MAE: 1.681485\n",
      "Epoch 119: MSE: 6.5390353, MAE: 1.6868788\n",
      "Epoch 120: MSE: 6.3628902, MAE: 1.6774005\n",
      "Epoch 121: MSE: 6.4139733, MAE: 1.6804674\n",
      "Epoch 122: MSE: 6.374036, MAE: 1.668001\n",
      "Epoch 123: MSE: 6.3056536, MAE: 1.6616365\n",
      "Epoch 124: MSE: 6.2988505, MAE: 1.6674911\n",
      "Epoch 125: MSE: 6.2318845, MAE: 1.6440086\n",
      "Epoch 126: MSE: 6.277898, MAE: 1.6463548\n",
      "Epoch 127: MSE: 6.1273627, MAE: 1.632937\n",
      "Epoch 128: MSE: 6.1557293, MAE: 1.6338397\n",
      "Epoch 129: MSE: 6.06003, MAE: 1.6340865\n",
      "Epoch 130: MSE: 5.9405212, MAE: 1.6218213\n",
      "Epoch 131: MSE: 6.032081, MAE: 1.6178811\n",
      "Epoch 132: MSE: 5.979238, MAE: 1.6148212\n",
      "Epoch 133: MSE: 5.9219484, MAE: 1.627572\n",
      "Epoch 134: MSE: 5.8830066, MAE: 1.599165\n",
      "Epoch 135: MSE: 5.8377557, MAE: 1.5967383\n",
      "Epoch 136: MSE: 5.831576, MAE: 1.6052316\n",
      "Epoch 137: MSE: 5.7305856, MAE: 1.5985204\n",
      "Epoch 138: MSE: 5.8332562, MAE: 1.5901157\n",
      "Epoch 139: MSE: 5.78548, MAE: 1.5758631\n",
      "Epoch 140: MSE: 5.6810055, MAE: 1.5821967\n",
      "Epoch 141: MSE: 5.6815696, MAE: 1.569185\n",
      "Epoch 142: MSE: 5.6349454, MAE: 1.5729066\n",
      "Epoch 143: MSE: 5.6179156, MAE: 1.5595964\n",
      "Epoch 144: MSE: 5.558913, MAE: 1.5591786\n",
      "Epoch 145: MSE: 5.563603, MAE: 1.5521095\n",
      "Epoch 146: MSE: 5.529739, MAE: 1.5520248\n",
      "Epoch 147: MSE: 5.427318, MAE: 1.548434\n",
      "Epoch 148: MSE: 5.2783694, MAE: 1.5395972\n",
      "Epoch 149: MSE: 5.4317064, MAE: 1.5338418\n",
      "Epoch 150: MSE: 5.4155803, MAE: 1.543342\n",
      "Epoch 151: MSE: 5.3363037, MAE: 1.5163671\n",
      "Epoch 152: MSE: 5.4479313, MAE: 1.5378374\n",
      "Epoch 153: MSE: 5.3749433, MAE: 1.526256\n",
      "Epoch 154: MSE: 5.2513227, MAE: 1.5360857\n",
      "Epoch 155: MSE: 5.3507724, MAE: 1.5071831\n",
      "Epoch 156: MSE: 5.254864, MAE: 1.522194\n",
      "Epoch 157: MSE: 5.1891913, MAE: 1.5007737\n",
      "Epoch 158: MSE: 5.1754513, MAE: 1.4895852\n",
      "Epoch 159: MSE: 5.2696047, MAE: 1.4813322\n",
      "Epoch 160: MSE: 5.132675, MAE: 1.4920598\n",
      "Epoch 161: MSE: 5.138301, MAE: 1.4790244\n",
      "Epoch 162: MSE: 5.1810074, MAE: 1.4747853\n",
      "Epoch 163: MSE: 4.9937696, MAE: 1.4764613\n",
      "Epoch 164: MSE: 5.1027155, MAE: 1.4710004\n",
      "Epoch 165: MSE: 5.030287, MAE: 1.4699103\n",
      "Epoch 166: MSE: 5.04262, MAE: 1.4585027\n",
      "Epoch 167: MSE: 4.981649, MAE: 1.455251\n",
      "Epoch 168: MSE: 4.984487, MAE: 1.4670831\n",
      "Epoch 169: MSE: 4.9848804, MAE: 1.4575887\n",
      "Epoch 170: MSE: 4.925728, MAE: 1.4597993\n",
      "Epoch 171: MSE: 4.831465, MAE: 1.4456006\n",
      "Epoch 172: MSE: 4.962035, MAE: 1.4437972\n",
      "Epoch 173: MSE: 4.8604093, MAE: 1.4497902\n",
      "Epoch 174: MSE: 4.737474, MAE: 1.4355531\n",
      "Epoch 175: MSE: 4.772961, MAE: 1.4163129\n",
      "Epoch 176: MSE: 4.761939, MAE: 1.4238741\n",
      "Epoch 177: MSE: 4.688494, MAE: 1.410846\n",
      "Epoch 178: MSE: 4.6534305, MAE: 1.4178269\n",
      "Epoch 179: MSE: 4.884511, MAE: 1.4128381\n",
      "Epoch 180: MSE: 4.5859222, MAE: 1.4196547\n",
      "Epoch 181: MSE: 4.6839595, MAE: 1.4156978\n",
      "Epoch 182: MSE: 4.579967, MAE: 1.4027728\n",
      "Epoch 183: MSE: 4.6377053, MAE: 1.3982314\n",
      "Epoch 184: MSE: 4.6634817, MAE: 1.3858835\n",
      "Epoch 185: MSE: 4.636195, MAE: 1.3947661\n",
      "Epoch 186: MSE: 4.5876827, MAE: 1.4016188\n",
      "Epoch 187: MSE: 4.4829173, MAE: 1.382351\n",
      "Epoch 188: MSE: 4.4077992, MAE: 1.3690956\n",
      "Epoch 189: MSE: 4.4834666, MAE: 1.389908\n",
      "Epoch 190: MSE: 4.5604773, MAE: 1.3739707\n",
      "Epoch 191: MSE: 4.541993, MAE: 1.3679297\n",
      "Epoch 192: MSE: 4.4907465, MAE: 1.3861258\n",
      "Epoch 193: MSE: 4.412979, MAE: 1.3715281\n",
      "Epoch 194: MSE: 4.3744226, MAE: 1.3577418\n",
      "Epoch 195: MSE: 4.450865, MAE: 1.3672491\n",
      "Epoch 196: MSE: 4.396288, MAE: 1.3568693\n",
      "Epoch 197: MSE: 4.4565215, MAE: 1.3693115\n",
      "Epoch 198: MSE: 4.303, MAE: 1.3648216\n",
      "Epoch 199: MSE: 4.233461, MAE: 1.3457325\n",
      "Epoch 200: MSE: 4.3311176, MAE: 1.3264955\n",
      "Epoch 201: MSE: 4.2226634, MAE: 1.3393142\n",
      "Epoch 202: MSE: 4.13207, MAE: 1.336597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: MSE: 4.320483, MAE: 1.3291465\n",
      "Epoch 204: MSE: 4.165603, MAE: 1.330326\n",
      "Epoch 205: MSE: 4.241249, MAE: 1.3336486\n",
      "Epoch 206: MSE: 4.216477, MAE: 1.3184489\n",
      "Epoch 207: MSE: 4.214923, MAE: 1.3288454\n",
      "Epoch 208: MSE: 4.150066, MAE: 1.3310262\n",
      "Epoch 209: MSE: 4.216714, MAE: 1.3221904\n",
      "Epoch 210: MSE: 4.0978446, MAE: 1.3073376\n",
      "Epoch 211: MSE: 4.082179, MAE: 1.3095741\n",
      "Epoch 212: MSE: 4.0718136, MAE: 1.3145651\n",
      "Epoch 213: MSE: 4.093467, MAE: 1.3036245\n",
      "Epoch 214: MSE: 4.0864687, MAE: 1.3080895\n",
      "Epoch 215: MSE: 3.8783185, MAE: 1.2985934\n",
      "Epoch 216: MSE: 4.0689015, MAE: 1.292163\n",
      "Epoch 217: MSE: 3.9020169, MAE: 1.2922064\n",
      "Epoch 218: MSE: 4.1929336, MAE: 1.2981677\n",
      "Epoch 219: MSE: 4.0180974, MAE: 1.298046\n",
      "Epoch 220: MSE: 3.9587352, MAE: 1.2802417\n",
      "Epoch 221: MSE: 3.9378943, MAE: 1.2807673\n",
      "Epoch 222: MSE: 3.998909, MAE: 1.2803402\n",
      "Epoch 223: MSE: 4.023903, MAE: 1.2728169\n",
      "Epoch 224: MSE: 3.8840501, MAE: 1.2615565\n",
      "Epoch 225: MSE: 3.8499162, MAE: 1.2610347\n",
      "Epoch 226: MSE: 3.8014207, MAE: 1.275032\n",
      "Epoch 227: MSE: 3.9487686, MAE: 1.2753415\n",
      "Epoch 228: MSE: 3.9015563, MAE: 1.2544942\n",
      "Epoch 229: MSE: 3.800181, MAE: 1.2486902\n",
      "Epoch 230: MSE: 3.9503276, MAE: 1.2531408\n",
      "Epoch 231: MSE: 3.7550154, MAE: 1.2286752\n",
      "Epoch 232: MSE: 3.8345325, MAE: 1.2390237\n",
      "Epoch 233: MSE: 3.7898498, MAE: 1.2341119\n",
      "Epoch 234: MSE: 3.8025832, MAE: 1.22351\n",
      "Epoch 235: MSE: 3.7650964, MAE: 1.2315476\n",
      "Epoch 236: MSE: 3.73506, MAE: 1.2267922\n",
      "Epoch 237: MSE: 3.720117, MAE: 1.2332363\n",
      "Epoch 238: MSE: 3.6983244, MAE: 1.2215865\n",
      "Epoch 239: MSE: 3.6732562, MAE: 1.2163874\n",
      "Epoch 240: MSE: 3.7635138, MAE: 1.2320893\n",
      "Epoch 241: MSE: 3.618366, MAE: 1.2085936\n",
      "Epoch 242: MSE: 3.7650557, MAE: 1.2199332\n",
      "Epoch 243: MSE: 3.7428637, MAE: 1.2252972\n",
      "Epoch 244: MSE: 3.521436, MAE: 1.2091949\n",
      "Epoch 245: MSE: 3.6078925, MAE: 1.2002785\n",
      "Epoch 246: MSE: 3.5325732, MAE: 1.1955549\n",
      "Epoch 247: MSE: 3.578757, MAE: 1.2042909\n",
      "Epoch 248: MSE: 3.5975275, MAE: 1.2009994\n",
      "Epoch 249: MSE: 3.6467295, MAE: 1.1985066\n",
      "Epoch 250: MSE: 3.5120833, MAE: 1.1966292\n",
      "Epoch 251: MSE: 3.4891744, MAE: 1.1883224\n",
      "Epoch 252: MSE: 3.5126276, MAE: 1.16971\n",
      "Epoch 253: MSE: 3.4164367, MAE: 1.1773543\n",
      "Epoch 254: MSE: 3.4729283, MAE: 1.1701602\n",
      "Epoch 255: MSE: 3.418705, MAE: 1.1838901\n",
      "Epoch 256: MSE: 3.5059328, MAE: 1.1743762\n",
      "Epoch 257: MSE: 3.5434206, MAE: 1.1689025\n",
      "Epoch 258: MSE: 3.4437332, MAE: 1.1588233\n",
      "Epoch 259: MSE: 3.4961472, MAE: 1.1561898\n",
      "Epoch 260: MSE: 3.4272153, MAE: 1.1639924\n",
      "Epoch 261: MSE: 3.4257317, MAE: 1.1616479\n",
      "Epoch 262: MSE: 3.4095612, MAE: 1.1486259\n",
      "Epoch 263: MSE: 3.3885424, MAE: 1.1591319\n",
      "Epoch 264: MSE: 3.3622556, MAE: 1.1439214\n",
      "Epoch 265: MSE: 3.4418907, MAE: 1.1567107\n",
      "Epoch 266: MSE: 3.4135249, MAE: 1.1466447\n",
      "Epoch 267: MSE: 3.3226192, MAE: 1.1611367\n",
      "Epoch 268: MSE: 3.2399802, MAE: 1.1372588\n",
      "Epoch 269: MSE: 3.2984884, MAE: 1.135792\n",
      "Epoch 270: MSE: 3.3041968, MAE: 1.1390754\n",
      "Epoch 271: MSE: 3.3744245, MAE: 1.1283668\n",
      "Epoch 272: MSE: 3.3148909, MAE: 1.1256961\n",
      "Epoch 273: MSE: 3.211421, MAE: 1.1216962\n",
      "Epoch 274: MSE: 3.4133372, MAE: 1.1391083\n",
      "Epoch 275: MSE: 3.3004243, MAE: 1.1302422\n",
      "Epoch 276: MSE: 3.2280083, MAE: 1.1319304\n",
      "Epoch 277: MSE: 3.1913588, MAE: 1.1214427\n",
      "Epoch 278: MSE: 3.246283, MAE: 1.1151148\n",
      "Epoch 279: MSE: 3.2037888, MAE: 1.1133537\n",
      "Epoch 280: MSE: 3.1074507, MAE: 1.1087807\n",
      "Epoch 281: MSE: 3.303307, MAE: 1.1128166\n",
      "Epoch 282: MSE: 3.2494495, MAE: 1.1093423\n",
      "Epoch 283: MSE: 3.1932118, MAE: 1.1045489\n",
      "Epoch 284: MSE: 3.0401523, MAE: 1.081845\n",
      "Epoch 285: MSE: 3.0625606, MAE: 1.0864441\n",
      "Epoch 286: MSE: 3.1843092, MAE: 1.1015466\n",
      "Epoch 287: MSE: 2.9783437, MAE: 1.0906613\n",
      "Epoch 288: MSE: 3.1681304, MAE: 1.0983182\n",
      "Epoch 289: MSE: 3.165488, MAE: 1.0894709\n",
      "Epoch 290: MSE: 3.2038264, MAE: 1.0935113\n",
      "Epoch 291: MSE: 2.9633784, MAE: 1.0794055\n",
      "Epoch 292: MSE: 3.1469624, MAE: 1.0830954\n",
      "Epoch 293: MSE: 3.1098595, MAE: 1.0864822\n",
      "Epoch 294: MSE: 3.143471, MAE: 1.0761994\n",
      "Epoch 295: MSE: 3.1148496, MAE: 1.0824115\n",
      "Epoch 296: MSE: 3.2158163, MAE: 1.0817771\n",
      "Epoch 297: MSE: 2.9604754, MAE: 1.0722238\n",
      "Epoch 298: MSE: 3.0004451, MAE: 1.0688508\n",
      "Epoch 299: MSE: 3.051996, MAE: 1.0704606\n",
      "Epoch 300: MSE: 3.1344044, MAE: 1.0825007\n",
      "Epoch 301: MSE: 3.0710378, MAE: 1.0681762\n",
      "Epoch 302: MSE: 2.9196763, MAE: 1.0659509\n",
      "Epoch 303: MSE: 3.0227423, MAE: 1.0671165\n",
      "Epoch 304: MSE: 2.8223119, MAE: 1.0583053\n",
      "Epoch 305: MSE: 2.9421756, MAE: 1.0603923\n",
      "Epoch 306: MSE: 3.0840793, MAE: 1.0547608\n",
      "Epoch 307: MSE: 2.963116, MAE: 1.0707351\n",
      "Epoch 308: MSE: 2.9589336, MAE: 1.050945\n",
      "Epoch 309: MSE: 2.828486, MAE: 1.052906\n",
      "Epoch 310: MSE: 2.9581144, MAE: 1.0571525\n",
      "Epoch 311: MSE: 3.066215, MAE: 1.0485303\n",
      "Epoch 312: MSE: 2.8140745, MAE: 1.0423284\n",
      "Epoch 313: MSE: 2.9437184, MAE: 1.0365525\n",
      "Epoch 314: MSE: 2.913923, MAE: 1.049725\n",
      "Epoch 315: MSE: 2.9737005, MAE: 1.0480328\n",
      "Epoch 316: MSE: 2.9877777, MAE: 1.0510399\n",
      "Epoch 317: MSE: 2.9312246, MAE: 1.0386635\n",
      "Epoch 318: MSE: 2.7960124, MAE: 1.0336323\n",
      "Epoch 319: MSE: 2.9099793, MAE: 1.0291349\n",
      "Epoch 320: MSE: 2.8496716, MAE: 1.0334963\n",
      "Epoch 321: MSE: 2.744467, MAE: 1.020718\n",
      "Epoch 322: MSE: 2.8658752, MAE: 1.0235575\n",
      "Epoch 323: MSE: 2.8490589, MAE: 1.023996\n",
      "Epoch 324: MSE: 2.7690127, MAE: 1.0261257\n",
      "Epoch 325: MSE: 2.813408, MAE: 1.0334234\n",
      "Epoch 326: MSE: 2.7295697, MAE: 1.0210623\n",
      "Epoch 327: MSE: 2.8730776, MAE: 1.0176564\n",
      "Epoch 328: MSE: 2.805121, MAE: 1.0262258\n",
      "Epoch 329: MSE: 2.8721654, MAE: 1.025675\n",
      "Epoch 330: MSE: 2.827376, MAE: 1.0198913\n",
      "Epoch 331: MSE: 2.6718829, MAE: 1.0017604\n",
      "Epoch 332: MSE: 2.7349308, MAE: 1.0147402\n",
      "Epoch 333: MSE: 2.8348858, MAE: 1.0076796\n",
      "Epoch 334: MSE: 2.5978124, MAE: 0.99392456\n",
      "Epoch 335: MSE: 2.7251024, MAE: 1.0038329\n",
      "Epoch 336: MSE: 2.6995616, MAE: 1.0143077\n",
      "Epoch 337: MSE: 2.6825318, MAE: 1.0080892\n",
      "Epoch 338: MSE: 2.7571132, MAE: 1.0136606\n",
      "Epoch 339: MSE: 2.6314077, MAE: 0.99508953\n",
      "Epoch 340: MSE: 2.7924292, MAE: 1.0125954\n",
      "Epoch 341: MSE: 2.594112, MAE: 0.99208707\n",
      "Epoch 342: MSE: 2.6926577, MAE: 1.0000061\n",
      "Epoch 343: MSE: 2.6340537, MAE: 0.9988792\n",
      "Epoch 344: MSE: 2.6562128, MAE: 0.99986374\n",
      "Epoch 345: MSE: 2.6177013, MAE: 0.97635674\n",
      "Epoch 346: MSE: 2.6205842, MAE: 0.97740656\n",
      "Epoch 347: MSE: 2.6782064, MAE: 0.98217624\n",
      "Epoch 348: MSE: 2.6074588, MAE: 0.9842161\n",
      "Epoch 349: MSE: 2.6668897, MAE: 0.9760284\n",
      "Epoch 350: MSE: 2.5970984, MAE: 0.97435886\n",
      "Epoch 351: MSE: 2.5536885, MAE: 0.98414844\n",
      "Epoch 352: MSE: 2.5433314, MAE: 0.970106\n",
      "Epoch 353: MSE: 2.5891232, MAE: 0.9781856\n",
      "Epoch 354: MSE: 2.564395, MAE: 0.9645322\n",
      "Epoch 355: MSE: 2.532991, MAE: 0.96370023\n",
      "Epoch 356: MSE: 2.5644205, MAE: 0.9689255\n",
      "Epoch 357: MSE: 2.5278897, MAE: 0.95658374\n",
      "Epoch 358: MSE: 2.5504773, MAE: 0.9539696\n",
      "Epoch 359: MSE: 2.6328242, MAE: 0.96769017\n",
      "Epoch 360: MSE: 2.503862, MAE: 0.9572969\n",
      "Epoch 361: MSE: 2.5950341, MAE: 0.97444427\n",
      "Epoch 362: MSE: 2.5850427, MAE: 0.9687191\n",
      "Epoch 363: MSE: 2.4725444, MAE: 0.95731264\n",
      "Epoch 364: MSE: 2.5872717, MAE: 0.95772564\n",
      "Epoch 365: MSE: 2.5278986, MAE: 0.9522873\n",
      "Epoch 366: MSE: 2.4947777, MAE: 0.9658035\n",
      "Epoch 367: MSE: 2.4302337, MAE: 0.93740284\n",
      "Epoch 368: MSE: 2.5182936, MAE: 0.95328414\n",
      "Epoch 369: MSE: 2.4330313, MAE: 0.9443373\n",
      "Epoch 370: MSE: 2.4952505, MAE: 0.9558164\n",
      "Epoch 371: MSE: 2.4734213, MAE: 0.94900036\n",
      "Epoch 372: MSE: 2.4108198, MAE: 0.943262\n",
      "Epoch 373: MSE: 2.4822311, MAE: 0.95233226\n",
      "Epoch 374: MSE: 2.5637093, MAE: 0.9525744\n",
      "Epoch 375: MSE: 2.4232647, MAE: 0.94062865\n",
      "Epoch 376: MSE: 2.4354722, MAE: 0.9364205\n",
      "Epoch 377: MSE: 2.3527818, MAE: 0.9389856\n",
      "Epoch 378: MSE: 2.5269697, MAE: 0.94965106\n",
      "Epoch 379: MSE: 2.3113198, MAE: 0.931043\n",
      "Epoch 380: MSE: 2.4493246, MAE: 0.9415238\n",
      "Epoch 381: MSE: 2.3807955, MAE: 0.939696\n",
      "Epoch 382: MSE: 2.4209766, MAE: 0.9307269\n",
      "Epoch 383: MSE: 2.338574, MAE: 0.9352437\n",
      "Epoch 384: MSE: 2.3347876, MAE: 0.9351357\n",
      "Epoch 385: MSE: 2.362317, MAE: 0.93517506\n",
      "Epoch 386: MSE: 2.411473, MAE: 0.9279021\n",
      "Epoch 387: MSE: 2.3538733, MAE: 0.9361783\n",
      "Epoch 388: MSE: 2.3436825, MAE: 0.9231593\n",
      "Epoch 389: MSE: 2.2822356, MAE: 0.91426194\n",
      "Epoch 390: MSE: 2.2717206, MAE: 0.90753144\n",
      "Epoch 391: MSE: 2.3598151, MAE: 0.9158286\n",
      "Epoch 392: MSE: 2.432391, MAE: 0.9157363\n",
      "Epoch 393: MSE: 2.2827716, MAE: 0.92600644\n",
      "Epoch 394: MSE: 2.3071005, MAE: 0.9105914\n",
      "Epoch 395: MSE: 2.2118819, MAE: 0.91571295\n",
      "Epoch 396: MSE: 2.2441978, MAE: 0.8981696\n",
      "Epoch 397: MSE: 2.164702, MAE: 0.91153264\n",
      "Epoch 398: MSE: 2.313128, MAE: 0.8997785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: MSE: 2.2844586, MAE: 0.90599674\n",
      "Epoch 400: MSE: 2.2733777, MAE: 0.907488\n",
      "Epoch 401: MSE: 2.311076, MAE: 0.9030893\n",
      "Epoch 402: MSE: 2.2640867, MAE: 0.9017223\n",
      "Epoch 403: MSE: 2.1602113, MAE: 0.89062256\n",
      "Epoch 404: MSE: 2.3093457, MAE: 0.91207016\n",
      "Epoch 405: MSE: 2.1866672, MAE: 0.9105302\n",
      "Epoch 406: MSE: 2.3001342, MAE: 0.90212286\n",
      "Epoch 407: MSE: 2.1460907, MAE: 0.90229183\n",
      "Epoch 408: MSE: 2.2725074, MAE: 0.8994973\n",
      "Epoch 409: MSE: 2.2293916, MAE: 0.8986188\n",
      "Epoch 410: MSE: 2.1361043, MAE: 0.88684016\n",
      "Epoch 411: MSE: 2.225958, MAE: 0.9000256\n",
      "Epoch 412: MSE: 2.1252863, MAE: 0.88071835\n",
      "Epoch 413: MSE: 2.1470757, MAE: 0.8934657\n",
      "Epoch 414: MSE: 2.1992998, MAE: 0.8869514\n",
      "Epoch 415: MSE: 2.1721327, MAE: 0.8987831\n",
      "Epoch 416: MSE: 2.1841474, MAE: 0.88617426\n",
      "Epoch 417: MSE: 2.1233883, MAE: 0.88085866\n",
      "Epoch 418: MSE: 2.2347264, MAE: 0.8854882\n",
      "Epoch 419: MSE: 2.0358164, MAE: 0.86812437\n",
      "Epoch 420: MSE: 2.1191883, MAE: 0.8866901\n",
      "Epoch 421: MSE: 2.1431487, MAE: 0.8898216\n",
      "Epoch 422: MSE: 2.2261324, MAE: 0.8919602\n",
      "Epoch 423: MSE: 2.1040819, MAE: 0.86763316\n",
      "Epoch 424: MSE: 2.1858258, MAE: 0.88095033\n",
      "Epoch 425: MSE: 2.028753, MAE: 0.8704131\n",
      "Epoch 426: MSE: 2.1390014, MAE: 0.8862065\n",
      "Epoch 427: MSE: 2.0744426, MAE: 0.85472804\n",
      "Epoch 428: MSE: 2.0898354, MAE: 0.88055557\n",
      "Epoch 429: MSE: 2.085742, MAE: 0.8722069\n",
      "Epoch 430: MSE: 2.081986, MAE: 0.8771484\n",
      "Epoch 431: MSE: 2.2036498, MAE: 0.8760316\n",
      "Epoch 432: MSE: 2.165203, MAE: 0.8800496\n",
      "Epoch 433: MSE: 2.1330047, MAE: 0.8731924\n",
      "Epoch 434: MSE: 2.0384843, MAE: 0.8646303\n",
      "Epoch 435: MSE: 2.06865, MAE: 0.8675492\n",
      "Epoch 436: MSE: 2.0679398, MAE: 0.8632586\n",
      "Epoch 437: MSE: 1.9722794, MAE: 0.8476226\n",
      "Epoch 438: MSE: 2.1774874, MAE: 0.8810996\n",
      "Epoch 439: MSE: 1.9467133, MAE: 0.83917326\n",
      "Epoch 440: MSE: 1.9951589, MAE: 0.85031\n",
      "Epoch 441: MSE: 1.9851689, MAE: 0.85300297\n",
      "Epoch 442: MSE: 1.9947606, MAE: 0.8618609\n",
      "Epoch 443: MSE: 2.0808105, MAE: 0.84252614\n",
      "Epoch 444: MSE: 1.8852241, MAE: 0.84102756\n",
      "Epoch 445: MSE: 2.109756, MAE: 0.85989606\n",
      "Epoch 446: MSE: 1.8822384, MAE: 0.83922255\n",
      "Epoch 447: MSE: 2.0075533, MAE: 0.8542686\n",
      "Epoch 448: MSE: 2.0829234, MAE: 0.84214646\n",
      "Epoch 449: MSE: 1.9932272, MAE: 0.8525129\n",
      "Epoch 450: MSE: 1.9328951, MAE: 0.83625734\n",
      "Epoch 451: MSE: 2.0902162, MAE: 0.8417234\n",
      "Epoch 452: MSE: 1.9464988, MAE: 0.8472294\n",
      "Epoch 453: MSE: 1.9985904, MAE: 0.8385397\n",
      "Epoch 454: MSE: 1.9653462, MAE: 0.84183407\n",
      "Epoch 455: MSE: 1.9927692, MAE: 0.8445846\n",
      "Epoch 456: MSE: 1.9662813, MAE: 0.8418435\n",
      "Epoch 457: MSE: 2.0473268, MAE: 0.84032714\n",
      "Epoch 458: MSE: 1.9181277, MAE: 0.8277966\n",
      "Epoch 459: MSE: 1.9268372, MAE: 0.8399922\n",
      "Epoch 460: MSE: 1.864029, MAE: 0.8401152\n",
      "Epoch 461: MSE: 1.9899989, MAE: 0.84000146\n",
      "Epoch 462: MSE: 1.943645, MAE: 0.8316354\n",
      "Epoch 463: MSE: 1.8428732, MAE: 0.80886894\n",
      "Epoch 464: MSE: 1.9312891, MAE: 0.8378947\n",
      "Epoch 465: MSE: 1.855892, MAE: 0.80717206\n",
      "Epoch 466: MSE: 2.0096188, MAE: 0.83655363\n",
      "Epoch 467: MSE: 1.8440166, MAE: 0.81868404\n",
      "Epoch 468: MSE: 1.8780645, MAE: 0.83343214\n",
      "Epoch 469: MSE: 1.8229104, MAE: 0.806747\n",
      "Epoch 470: MSE: 1.9315906, MAE: 0.82661617\n",
      "Epoch 471: MSE: 1.9414728, MAE: 0.8029257\n",
      "Epoch 472: MSE: 1.8532323, MAE: 0.8105959\n",
      "Epoch 473: MSE: 1.8227774, MAE: 0.82004887\n",
      "Epoch 474: MSE: 1.8242803, MAE: 0.80777836\n",
      "Epoch 475: MSE: 1.7825737, MAE: 0.8058585\n",
      "Epoch 476: MSE: 1.9065623, MAE: 0.8306146\n",
      "Epoch 477: MSE: 1.8493273, MAE: 0.8252344\n",
      "Epoch 478: MSE: 1.893589, MAE: 0.7967342\n",
      "Epoch 479: MSE: 1.8702384, MAE: 0.82116306\n",
      "Epoch 480: MSE: 1.7590008, MAE: 0.79032713\n",
      "Epoch 481: MSE: 1.8211659, MAE: 0.8094723\n",
      "Epoch 482: MSE: 1.7865626, MAE: 0.803477\n",
      "Epoch 483: MSE: 1.7486751, MAE: 0.79770476\n",
      "Epoch 484: MSE: 1.8329257, MAE: 0.79406494\n",
      "Epoch 485: MSE: 1.7738364, MAE: 0.8086988\n",
      "Epoch 486: MSE: 1.8522067, MAE: 0.8059893\n",
      "Epoch 487: MSE: 1.7955235, MAE: 0.8019845\n",
      "Epoch 488: MSE: 1.8513364, MAE: 0.80016387\n",
      "Epoch 489: MSE: 1.7968056, MAE: 0.79997\n",
      "Epoch 490: MSE: 1.8162246, MAE: 0.8088185\n",
      "Epoch 491: MSE: 1.7967374, MAE: 0.8038838\n",
      "Epoch 492: MSE: 1.8093047, MAE: 0.8229724\n",
      "Epoch 493: MSE: 1.701946, MAE: 0.7806489\n",
      "Epoch 494: MSE: 1.8205851, MAE: 0.78374106\n",
      "Epoch 495: MSE: 1.7018056, MAE: 0.78517044\n",
      "Epoch 496: MSE: 1.7815999, MAE: 0.7877564\n",
      "Epoch 497: MSE: 1.7715365, MAE: 0.8021201\n",
      "Epoch 498: MSE: 1.6804531, MAE: 0.7726433\n",
      "Epoch 499: MSE: 1.7614081, MAE: 0.80010897\n",
      "Epoch 500: MSE: 1.743581, MAE: 0.78249604\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1...epochCount {\n",
    "    var epochLoss: Float = 0\n",
    "    var epochMAE: Float = 0\n",
    "    var batchCount: Int = 0\n",
    "    var batchArray = Array(repeating: false, count: numberOfBatch)\n",
    "    for batch in 0..<numberOfBatch {\n",
    "        var r = batch\n",
    "        if shuffle {\n",
    "            while true {\n",
    "                r = Int.random(in: 0..<numberOfBatch)\n",
    "                if !batchArray[r] {\n",
    "                    batchArray[r] = true\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        let batchStart = r * batchSize\n",
    "        let batchEnd = min(xTrain.count, batchStart + batchSize)\n",
    "        let (loss, grad) = model.valueWithGradient { (model: RegressionModel) -> Tensor<Float> in\n",
    "            let logits = model(XTrain[batchStart..<batchEnd])\n",
    "            return meanSquaredError(predicted: logits, expected: YTrain[batchStart..<batchEnd])\n",
    "        }\n",
    "        optimizer.update(&model, along: grad)\n",
    "        \n",
    "        let logits = model(XTrain[batchStart..<batchEnd])\n",
    "        epochMAE += mae(predictions: logits, truths: YTrain[batchStart..<batchEnd])\n",
    "        epochLoss += loss.scalarized()\n",
    "        batchCount += 1\n",
    "    }\n",
    "    epochMAE /= Float(batchCount)\n",
    "    epochLoss /= Float(batchCount)\n",
    "\n",
    "    print(\"Epoch \\(epoch): MSE: \\(epochLoss), MAE: \\(epochMAE)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.336266] [22.6]\r\n",
      "[[22.336267]]\r\n",
      "[20.049778] [18.9]\r\n",
      "MSE: 6.1216507, MAE: 1.8418174\r\n"
     ]
    }
   ],
   "source": [
    "Context.local.learningPhase = .inference\n",
    "\n",
    "let cheat = model(XTrain)\n",
    "print(cheat[0], YTrain[0])\n",
    "\n",
    "let record: [Float] = [-0.4013274553772651,-0.48782210614046656,-1.1729760489283325,-0.2721895900613162,-0.8055945265354896,0.09156749405417394,-1.828902543802867,0.6384789935042571,-0.6351491942719604,0.1472680456555187,-0.7178137893787737,0.2073805740660824,-0.7473489168521552] \n",
    "let tfrecord = Tensor<Float>(record).reshaped(to: TensorShape([1, 13]))\n",
    "let tfcheat = model(tfrecord)\n",
    "print(tfcheat)\n",
    "\n",
    "let prediction = model(XTest)\n",
    "print(prediction[0], YTest[0])\n",
    "\n",
    "let tmse = meanSquaredError(predicted: prediction, expected: YTest).scalarized()\n",
    "let tmae = mae(predictions: prediction, truths: YTest)\n",
    "\n",
    "print(\"MSE: \\(tmse), MAE: \\(tmae)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fkf29HLlohIP"
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 64] [64, 32] [32, 1]\r\n",
      "[64] [32] [1]\r\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1.weight.shape, model.layer2.weight.shape, model.layer3.weight.shape)\n",
    "print(model.layer1.bias.shape, model.layer2.bias.shape, model.layer3.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "let coremlModel = Model(version: 4,\n",
    "                        shortDescription: \"Regression\",\n",
    "                        author: \"Jacopo Mangiavacchi\",\n",
    "                        license: \"MIT\",\n",
    "                        userDefined: [\"SwiftCoremltoolsVersion\" : \"0.0.3\"]) {\n",
    "    Input(name: \"input\", shape: [13], featureType: .Double)\n",
    "    Output(name: \"output\", shape: [1], featureType: .Double)\n",
    "    NeuralNetwork {\n",
    "        InnerProduct(name: \"dense1\",\n",
    "                     input: [\"input\"],\n",
    "                     output: [\"outDense1\"],\n",
    "                     weights: model.layer1.weight.flattened().scalars,\n",
    "                     bias: model.layer1.bias.flattened().scalars,\n",
    "                     inputChannels: 13,\n",
    "                     outputChannels: 64,\n",
    "                     updatable: false)\n",
    "        ReLu(name: \"Relu1\",\n",
    "             input: [\"outDense1\"],\n",
    "             output: [\"outRelu1\"])\n",
    "        InnerProduct(name: \"dense2\",\n",
    "                     input: [\"outRelu1\"],\n",
    "                     output: [\"outDense2\"],\n",
    "                     weights: model.layer2.weight.flattened().scalars,\n",
    "                     bias: model.layer2.bias.flattened().scalars,\n",
    "                     inputChannels: 64,\n",
    "                     outputChannels: 32,\n",
    "                     updatable: false)\n",
    "        ReLu(name: \"Relu2\",\n",
    "             input: [\"outDense2\"],\n",
    "             output: [\"outRelu2\"])\n",
    "        InnerProduct(name: \"dense3\",\n",
    "                     input: [\"outRelu2\"],\n",
    "                     output: [\"output\"],\n",
    "                     weights: model.layer3.weight.flattened().scalars,\n",
    "                     bias: model.layer3.bias.flattened().scalars,\n",
    "                     inputChannels: 32,\n",
    "                     outputChannels: 1,\n",
    "                     updatable: false)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "let coreMLData = coremlModel.coreMLData\n",
    "try! coreMLData!.write(to: URL(fileURLWithPath: \"../model/s4tf_train_model.mlmodel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF_House.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
